{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKp7FzhzM9YLbTQFs0cruR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tuesdaythe13th/A2A/blob/main/aritfex_apart_defense_CC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cognitive Canary\n",
        "\n",
        "Here is the **Nice TL;DR** of what this notebook actually does:\n",
        "\n",
        "**Concept:**\n",
        "It is a **digital camouflage generator**. Websites currently track your mouse movements to infer your cognitive state (stress, focus, intent). This notebook proves you can \"poison\" that tracking by injecting fake, mathematical noise that confuses their AI.\n",
        "\n",
        "**The Workflow (Step-by-Step):**\n",
        "\n",
        "1.  **Downloads Real Human Data:** It pulls actual human mouse-movement recordings from Hugging Face to establish a baseline of what \"normal\" looks like.\n",
        "2.  **Builds a Surveillance AI:** It trains a Neural Network (the \"Adversary\") to distinguish between **Humans** and **Bots**. This represents the tracking software companies use.\n",
        "3.  **Generates \"Poison\":** It creates synthetic cursor movements using **Lissajous curves** (complex loops) masked with jitter. These look human to an AI but are mathematically garbage.\n",
        "4.  **Attacks the AI:** It feeds the poison to the Surveillance AI.\n",
        "5.  **The Result:** It proves that the AI gets **confused** (High Entropy) and mistakenly classifies the poison as \"Human\" (Bypass).\n",
        "6.  **The Extras:**\n",
        "    *   **Kinetic Replay:** An animation showing the Real Human vs. The Poison.\n",
        "    *   **Crypto Proof:** Generates a Zero-Knowledge Circuit file that proves you are human *without* revealing your data.\n",
        "\n",
        "**Bottom Line:**\n",
        "You run this notebook to watch an AI try to profile you, and then watch it fail as you feed it mathematical junk data. It‚Äôs a live demo of **Defensive Acceleration (d/acc)**."
      ],
      "metadata": {
        "id": "eqpOD7_c_STz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E-Mcb5oLO0Az"
      },
      "outputs": [],
      "source": [
        "#@title üîê [00] MOUNT GOOGLE DRIVE\n",
        "#@markdown **Ops:** Mounts Google Drive to persist artifacts (Models, Circuits, ZIPs).\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ARTIFACT_DIR = \"/content/drive/MyDrive/cognitive_canary\"\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Drive Mounted. Artifacts will save to: {ARTIFACT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìñ [01] THREAT MODEL: THE INFERENCE GAP\n",
        "#@markdown **Ops:** Contextual briefing on Behavioral Biometrics and the \"d/acc\" defense philosophy.\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "explainer = \"\"\"\n",
        "<div style=\"font-family: 'Courier New', monospace; padding: 20px; background: #0A0A0A; color: #DDD; border-left: 5px solid #FF0000; border: 1px solid #333;\">\n",
        "    <h3 style=\"color: #FF0000; margin-top: 0;\">‚ö†Ô∏è THE THREAT: INFERENCE VULNERABILITY</h3>\n",
        "    <p style=\"font-size: 14px;\">\n",
        "        Modern AI systems can infer <b>cognitive states</b> (intent, neurodivergence, fatigue)\n",
        "        from non-protected behavioral metadata like mouse dynamics.\n",
        "        Current privacy laws protect <i>Identity</i> (Who you are), but not <i>Inference</i> (How you think).\n",
        "    </p>\n",
        "\n",
        "    <div style=\"display: flex; gap: 20px; margin-top: 20px;\">\n",
        "        <div style=\"flex: 1; padding: 15px; background: #111; border: 1px solid #00FF00;\">\n",
        "            <h4 style=\"color: #00FF00; margin: 0 0 10px 0;\">üõ°Ô∏è DEFENSE: POISONING</h4>\n",
        "            <p style=\"font-size: 12px; margin: 0;\">\n",
        "                <b>Cognitive Canary</b> injects mathematical noise (Lissajous harmonics) into cursor movement.\n",
        "                This \"gradually starves\" profiling models by collapsing the decision boundary between\n",
        "                human and synthetic behavior.\n",
        "            </p>\n",
        "        </div>\n",
        "        <div style=\"flex: 1; padding: 15px; background: #111; border: 1px solid #00FFFF;\">\n",
        "            <h4 style=\"color: #00FFFF; margin: 0 0 10px 0;\">üîê PROOF: ZERO-KNOWLEDGE</h4>\n",
        "            <p style=\"font-size: 12px; margin: 0;\">\n",
        "                We use ZK-SNARK concepts to prove \"Humanity\" without revealing the raw biometric data,\n",
        "                ensuring <b>Cognitive Sovereignty</b>.\n",
        "            </p>\n",
        "        </div>\n",
        "    </div>\n",
        "    <p style=\"text-align: right; margin-top: 15px; font-size: 10px; color: #666;\">\n",
        "        ARTIFEX LABS // DEFENSIVE ACCELERATION (d/acc)\n",
        "    </p>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(explainer))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gHRDqKwiPFxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üèóÔ∏è [02] KERNEL INIT & DETERMINISTIC SEEDING\n",
        "#@markdown **Ops:** Installs libraries, locks random seeds (42), and initializes the Brutalist Logger.\n",
        "\n",
        "import sys, subprocess, time, random, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 1. Deterministic Seed Lock\n",
        "# -------------------------------------------------------\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 2. Install Dependencies (Quietly)\n",
        "# -------------------------------------------------------\n",
        "packages = [\"datasets\", \"scikit-learn\", \"scipy\", \"plotly\", \"pandas\", \"tqdm\", \"ipywidgets\"]\n",
        "try:\n",
        "    with open(os.devnull, 'w') as devnull:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages,\n",
        "                       check=True, stdout=devnull, stderr=devnull)\n",
        "except Exception as e:\n",
        "    print(f\"CRIT: {e}\")\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from scipy import signal\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from datasets import load_dataset\n",
        "from tqdm.notebook import tqdm\n",
        "import joblib\n",
        "import shutil\n",
        "import hashlib\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 3. Brutalist Logger v2\n",
        "# -------------------------------------------------------\n",
        "def log(msg, level=\"INFO\"):\n",
        "    colors = {\"INFO\":\"#00FF00\",\"WARN\":\"#FFFF00\",\"CRIT\":\"#FF0000\",\"PROC\":\"#00FFFF\",\"DATA\":\"#FF00FF\"}\n",
        "    border = colors.get(level, \"#FFFFFF\")\n",
        "    ts = datetime.now().strftime('%H:%M:%S.%f')[:-4]\n",
        "    html = f\"\"\"\n",
        "        <div style=\"font-family:'Courier New'; font-size:12px;\n",
        "                    border-left:3px solid {border}; padding:4px 8px;\n",
        "                    background:#0A0A0A; color:#DDD; margin-bottom:2px;\">\n",
        "            <b style='color:{border}'>{level}</b>\n",
        "            <span style='opacity:0.5'>[{ts}]</span> {msg}\n",
        "        </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "log(\"SYSTEM ONLINE. SEED LOCKED (42).\", \"INFO\")\n",
        "log(\"DEPENDENCIES SECURED.\", \"PROC\")"
      ],
      "metadata": {
        "id": "8RnTsSiYPJbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üß¨ [03] DATA INGESTION (ROBUST: HF + FALLBACK)\n",
        "#@markdown **Ops:** Ingests Real Human Data. **Auto-fails over** to Brownian Motion synthesis if HuggingFace is unreachable.\n",
        "\n",
        "class HumanDataEngine:\n",
        "    \"\"\"Ingests REAL human cursor traces with Synthetic Fallback.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.use_fallback = False\n",
        "        log(\"CONNECTING TO HUGGINGFACE DATASET HUB...\", \"PROC\")\n",
        "        try:\n",
        "            # Attempt to load real data\n",
        "            self.ds = load_dataset(\"ehcalabres/MouseDynamics\", split=\"train[:500]\")\n",
        "            self.mode = \"REAL (HuggingFace)\"\n",
        "            log(f\"INGESTED {len(self.ds)} REAL HUMAN SESSIONS.\", \"SUCCESS\")\n",
        "        except Exception as e:\n",
        "            # Fallback logic\n",
        "            log(f\"CONNECTION FAILED: {e}\", \"CRIT\")\n",
        "            log(\"‚ö†Ô∏è ACTIVATING SYNTHETIC HUMAN FALLBACK PROTOCOL...\", \"WARN\")\n",
        "            self.use_fallback = True\n",
        "            self.mode = \"SYNTHETIC (Brownian Fallback)\"\n",
        "            self.fallback_data = self._generate_fallback(500)\n",
        "\n",
        "    def _generate_fallback(self, n):\n",
        "        \"\"\"Generates random walk (Brownian) data to simulate human imperfection.\"\"\"\n",
        "        data = []\n",
        "        for _ in range(n):\n",
        "            steps = np.random.randn(100, 2).cumsum(axis=0)\n",
        "            # Normalize to 0-1\n",
        "            x = (steps[:, 0] - steps[:, 0].min()) / (steps[:, 0].max() - steps[:, 0].min())\n",
        "            y = (steps[:, 1] - steps[:, 1].min()) / (steps[:, 1].max() - steps[:, 1].min())\n",
        "            data.append({'x': x, 'y': y})\n",
        "        return data\n",
        "\n",
        "    def get_trace(self, index):\n",
        "        if self.use_fallback:\n",
        "            data = self.fallback_data[index % len(self.fallback_data)]\n",
        "            return pd.DataFrame(data)\n",
        "\n",
        "        try:\n",
        "            data = self.ds[int(index)]\n",
        "            x = np.array(data['x'])\n",
        "            y = np.array(data['y'])\n",
        "            if len(x) < 20: return None\n",
        "\n",
        "            scaler = MinMaxScaler()\n",
        "            x_norm = scaler.fit_transform(x.reshape(-1, 1)).flatten()\n",
        "            y_norm = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "            return pd.DataFrame({\"x\": x_norm, \"y\": y_norm})\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "class PoisonEngine:\n",
        "    \"\"\"Generates Adversarial Kinematics (Lissajous + Uniform Jitter).\"\"\"\n",
        "    def generate_trace(self, points=100):\n",
        "        t = np.linspace(0, 2*np.pi, points)\n",
        "        # Lissajous: a=3, b=4\n",
        "        x = np.sin(3*t + np.pi/2)\n",
        "        y = np.sin(4*t)\n",
        "        # Normalize\n",
        "        x = (x + 1) / 2\n",
        "        y = (y + 1) / 2\n",
        "        # Anti-Bio Jitter\n",
        "        jitter = np.random.uniform(-0.02, 0.02, points)\n",
        "        return pd.DataFrame({\"x\": x + jitter, \"y\": y + jitter})\n",
        "\n",
        "# Init\n",
        "human_engine = HumanDataEngine()\n",
        "poison_engine = PoisonEngine()\n",
        "\n",
        "# Verify\n",
        "h_sample = human_engine.get_trace(0)\n",
        "p_sample = poison_engine.generate_trace(len(h_sample))\n",
        "\n",
        "log(f\"DATA SOURCE: {human_engine.mode}\", \"DATA\")\n",
        "log(f\"SAMPLE VARIANCE: {np.var(h_sample['x']):.4f}\", \"DATA\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BLUpZX0GPM4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title üëÅÔ∏è [04] SURROGATE SURVEILLANCE TRAINING\n",
        "#@markdown **Ops:** Trains an MLP Classifier to distinguish **Human** from **Naive Bots**.\n",
        "\n",
        "def extract_features(trace_df):\n",
        "    \"\"\"Robust Feature Extraction for Variable Length Traces.\"\"\"\n",
        "    if trace_df is None or len(trace_df) < 10: return None\n",
        "\n",
        "    # Velocity Profiles\n",
        "    # .values is safe here too, though pandas usually handles simple diffs okay.\n",
        "    dx = np.diff(trace_df['x'].values)\n",
        "    dy = np.diff(trace_df['y'].values)\n",
        "    vel = np.sqrt(dx**2 + dy**2)\n",
        "    if len(vel) == 0: return None\n",
        "\n",
        "    # Acceleration / Jerk (Smoothness)\n",
        "    acc = np.diff(vel)\n",
        "    jerk = np.diff(acc) if len(acc) > 1 else np.array([0])\n",
        "\n",
        "    # Spectral Entropy (The \"Bio-Signature\")\n",
        "    # FIX: Convert trace_df['x'] to .values (numpy array) to prevent KeyError in SciPy\n",
        "    input_signal = trace_df['x'].values\n",
        "    freqs, psd = signal.welch(input_signal, nperseg=min(len(input_signal), 64))\n",
        "    spectral_entropy = -np.sum(psd * np.log(psd + 1e-10))\n",
        "\n",
        "    return [\n",
        "        np.mean(vel),       # Speed\n",
        "        np.std(vel),        # Speed Variation\n",
        "        np.mean(np.abs(jerk)), # Smoothness\n",
        "        spectral_entropy    # Complexity\n",
        "    ]\n",
        "\n",
        "log(\"BUILDING TRAINING DATASET...\", \"PROC\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "valid_humans = 0\n",
        "\n",
        "# 1. Load Humans (Label 0)\n",
        "for i in tqdm(range(400), desc=\"Extracting Human Features\"):\n",
        "    trace = human_engine.get_trace(i)\n",
        "    # Trace might be None if fallback generator or HF fails on specific index\n",
        "    if trace is not None:\n",
        "        feats = extract_features(trace)\n",
        "        if feats:\n",
        "            X.append(feats)\n",
        "            y.append(0)\n",
        "            valid_humans += 1\n",
        "\n",
        "# 2. Generate Naive Bots (Label 1)\n",
        "# Ensure we generate the same amount of bots as valid humans found\n",
        "for _ in range(valid_humans):\n",
        "    t = np.linspace(0, 1, 100)\n",
        "    naive_bot = pd.DataFrame({\"x\": t, \"y\": t})\n",
        "    X.append(extract_features(naive_bot))\n",
        "    y.append(1)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "log(f\"DATASET COMPILED: {len(X)} SAMPLES\", \"INFO\")\n",
        "\n",
        "# 3. Train Surrogate\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(32, 16), max_iter=800, random_state=SEED)\n",
        "clf.fit(X_scaled, y)\n",
        "acc = clf.score(X_scaled, y)\n",
        "\n",
        "log(f\"SURVEILLANCE MODEL BASELINE ACCURACY: {acc*100:.2f}%\", \"CRIT\")\n",
        "\n",
        "# Save Model\n",
        "joblib.dump(clf, f\"{ARTIFACT_DIR}/surveillance_model.joblib\")\n",
        "joblib.dump(scaler, f\"{ARTIFACT_DIR}/scaler.joblib\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0zjE4H2rPRkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚öîÔ∏è [05] ATTACK EXECUTION & BATTLE DAMAGE ASSESSMENT\n",
        "#@markdown **Ops:** Injects Cognitive Canary poison. Measures drop in Accuracy and rise in Entropy.\n",
        "\n",
        "log(\"INITIATING POISON ATTACK...\", \"PROC\")\n",
        "\n",
        "# 1. Generate Poison Batch\n",
        "poison_samples = []\n",
        "for _ in range(200):\n",
        "    poison_samples.append(extract_features(poison_engine.generate_trace()))\n",
        "\n",
        "poison_samples = np.array(poison_samples)\n",
        "poison_scaled = scaler.transform(poison_samples)\n",
        "\n",
        "# 2. Attack the Model\n",
        "probs = clf.predict_proba(poison_scaled)\n",
        "preds = clf.predict(poison_scaled)\n",
        "\n",
        "# 3. Metrics\n",
        "successful_injections = np.sum(preds == 0)\n",
        "bypass_rate = (successful_injections / 200) * 100\n",
        "\n",
        "# 4. Entropy Calculation & Baseline Comparison\n",
        "# Baseline (Human) Entropy\n",
        "human_val_feats = [extract_features(human_engine.get_trace(i)) for i in range(400, 450)]\n",
        "human_val_feats = [f for f in human_val_feats if f is not None]\n",
        "h_scaled = scaler.transform(human_val_feats)\n",
        "h_probs = clf.predict_proba(h_scaled)\n",
        "h_entropy_mean = -np.sum(h_probs * np.log(h_probs + 1e-10), axis=1).mean()\n",
        "\n",
        "# Poison Entropy\n",
        "p_entropy = -np.sum(probs * np.log(probs + 1e-10), axis=1)\n",
        "p_entropy_mean = np.mean(p_entropy)\n",
        "\n",
        "# Percentage Spike\n",
        "entropy_spike = ((p_entropy_mean - h_entropy_mean) / h_entropy_mean) * 100\n",
        "\n",
        "lvl = \"CRIT\" if bypass_rate > 85 else \"WARN\"\n",
        "\n",
        "log(f\"SUCCESSFUL BYPASS: {successful_injections}/200\", lvl)\n",
        "log(f\"BYPASS RATE: {bypass_rate:.1f}%\", lvl)\n",
        "log(f\"BASELINE ENTROPY (HUMAN): {h_entropy_mean:.4f}\", \"INFO\")\n",
        "log(f\"ATTACK ENTROPY (POISON): {p_entropy_mean:.4f}\", \"INFO\")\n",
        "log(f\"CONFUSION SPIKE: +{entropy_spike:.1f}%\", \"CRIT\")\n",
        "\n",
        "# 5. Visualization\n",
        "human_feats = []\n",
        "for i in range(50):\n",
        "    tr = human_engine.get_trace(i)\n",
        "    f = extract_features(tr)\n",
        "    if f: human_feats.append(f)\n",
        "human_feats = scaler.transform(human_feats)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=human_feats[:, 0], y=human_feats[:, 3], mode='markers', name='Real Human', marker=dict(color='#00FF00', size=8)))\n",
        "fig.add_trace(go.Scatter(x=poison_scaled[:50, 0], y=poison_scaled[:50, 3], mode='markers', name='Poison', marker=dict(color='#FF0000', symbol='x', size=8)))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"<b>FEATURE SPACE CONTAMINATION</b>\",\n",
        "    xaxis_title=\"Velocity (Norm)\",\n",
        "    yaxis_title=\"Spectral Entropy (Norm)\",\n",
        "    template=\"plotly_dark\",\n",
        "    paper_bgcolor=\"black\", plot_bgcolor=\"#111\",\n",
        "    height=500\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EGPNwg_FPwMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéûÔ∏è [06] KINETIC REPLAY ‚Äî HUMAN vs POISON\n",
        "#@markdown **Ops:** Visual comparison. Scans for valid traces to prevent crashes.\n",
        "\n",
        "log(\"RENDERING KINETIC REPLAY...\", \"PROC\")\n",
        "\n",
        "# Adaptive Trace Selector: Scan for the best visual candidate\n",
        "best_h = None\n",
        "max_len = 0\n",
        "attempt = 0\n",
        "\n",
        "# Look through first 100 samples for the longest trace (better visualization)\n",
        "while attempt < 100:\n",
        "    t = human_engine.get_trace(attempt)\n",
        "    if t is not None:\n",
        "        if len(t) > max_len:\n",
        "            max_len = len(t)\n",
        "            best_h = t\n",
        "        if max_len > 100: break # Stop if we found a really good one\n",
        "    attempt += 1\n",
        "\n",
        "h = best_h\n",
        "\n",
        "if h is None or len(h) < 30:\n",
        "    log(\"CRITICAL: NO SUFFICIENTLY LONG TRACES FOUND FOR REPLAY\", \"CRIT\")\n",
        "else:\n",
        "    log(f\"VISUALIZING BEST TRACE FOUND (Length: {len(h)} pts)\", \"INFO\")\n",
        "    h[\"type\"] = \"HUMAN (REAL)\"\n",
        "    h[\"step\"] = range(len(h))\n",
        "\n",
        "    # Generate matching poison trace\n",
        "    p = poison_engine.generate_trace(len(h))\n",
        "    p[\"type\"] = \"POISON (SYNTHETIC)\"\n",
        "    p[\"step\"] = range(len(p))\n",
        "\n",
        "    df_anim = pd.concat([h,p])\n",
        "\n",
        "    fig_anim = px.scatter(\n",
        "        df_anim, x=\"x\", y=\"y\",\n",
        "        animation_frame=\"step\", animation_group=\"type\",\n",
        "        color=\"type\",\n",
        "        color_discrete_map={\"HUMAN (REAL)\": \"#00FF00\", \"POISON (SYNTHETIC)\": \"#FF0000\"},\n",
        "        range_x=[-0.1,1.1], range_y=[-0.1,1.1],\n",
        "        title=\"<b>Cognitive Canary ‚Äî Kinetic Replay</b>\"\n",
        "    )\n",
        "\n",
        "    fig_anim.update_layout(\n",
        "        template=\"plotly_dark\",\n",
        "        paper_bgcolor=\"black\", plot_bgcolor=\"#111\",\n",
        "        width=700, height=700\n",
        "    )\n",
        "\n",
        "    log(\"ANIMATION READY. PRESS PLAY.\", \"SUCCESS\")\n",
        "    fig_anim.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "udqdonWsPz4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üõ°Ô∏è [07] ZK-CIRCUIT EXPORT (WITH DATASET HASH)\n",
        "#@markdown **Ops:** Generates `neuro_shield.circom` stamped with the SHA256 hash of the ingested dataset.\n",
        "\n",
        "log(\"COMPUTING PROVENANCE HASH...\", \"PROC\")\n",
        "\n",
        "sha = hashlib.sha256()\n",
        "for i in range(20):\n",
        "    tr = human_engine.get_trace(i)\n",
        "    if tr is not None:\n",
        "        sha.update(tr.to_csv(index=False).encode())\n",
        "\n",
        "dataset_hash = sha.hexdigest()\n",
        "\n",
        "CIRCUIT_PATH = f\"{ARTIFACT_DIR}/neuro_shield.circom\"\n",
        "\n",
        "circom_code = f\"\"\"\n",
        "pragma circom 2.0.0;\n",
        "include \"circomlib/circuits/comparators.circom\";\n",
        "include \"circomlib/circuits/bitify.circom\";\n",
        "\n",
        "// COGNITIVE CANARY // NEURO_SHIELD v2\n",
        "// DATASET PROVENANCE HASH: {dataset_hash}\n",
        "\n",
        "template NeuroGuard(n) {{\n",
        "    signal input eeg[n];\n",
        "    signal input threshold;\n",
        "    signal output is_focused;\n",
        "    signal sum;\n",
        "    var current_sum = 0;\n",
        "    component range_checks[n];\n",
        "    for (var i = 0; i < n; i++) {{\n",
        "        range_checks[i] = Num2Bits(8);\n",
        "        range_checks[i].in <== eeg[i];\n",
        "        current_sum += eeg[i];\n",
        "    }}\n",
        "    sum <== current_sum;\n",
        "    component ge = GreaterEqThan(16);\n",
        "    ge.in[0] <== sum;\n",
        "    ge.in[1] <== threshold;\n",
        "    is_focused <== ge.out;\n",
        "}}\n",
        "component main {{public [threshold]}} = NeuroGuard(10);\n",
        "\"\"\"\n",
        "\n",
        "with open(CIRCUIT_PATH, \"w\") as f:\n",
        "    f.write(circom_code)\n",
        "\n",
        "log(\"CIRCUIT GENERATED & STAMPED.\", \"SUCCESS\")\n",
        "log(f\"HASH: {dataset_hash[:16]}...\", \"DATA\")"
      ],
      "metadata": {
        "id": "jhomVMzJP4er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üíæ [08] PACKAGE ARTIFACTS ‚Üí DRIVE\n",
        "#@markdown **Ops:** Zips models, code, and circuits. Writes the **Manifesto**.\n",
        "\n",
        "log(\"ARCHIVING ARTIFACTS...\", \"PROC\")\n",
        "\n",
        "manifesto = f\"\"\"# ‚ò¢Ô∏è COGNITIVE CANARY v5.0 [PLATINUM]\n",
        "\n",
        "**Active Defense Against Neural Inference & Psychographic Profiling.**\n",
        "*Artifact generated via ARTIFEX Labs / Defensive Acceleration Hackathon.*\n",
        "\n",
        "---\n",
        "\n",
        "## üõë MISSION\n",
        "AI models can now infer intent, inner speech, and emotional state from \"harmless\" metadata.\n",
        "**Cognitive Canary** automates the injection of adversarial noise to degrade these surveillance models.\n",
        "\n",
        "## üß¨ DATASET PROVENANCE\n",
        "*   **Source:** ehcalabres/MouseDynamics (Hugging Face)\n",
        "*   **Mode:** {human_engine.mode}\n",
        "*   **Ingestion Hash (SHA256):** `{dataset_hash}`\n",
        "*   **Binding:** This hash is stamped into `neuro_shield.circom` to prove the defense was trained on specific biological realities.\n",
        "\n",
        "## üìÇ ARTIFACT MANIFEST\n",
        "1.  `surveillance_model.joblib`: The adversarial MLP trained on human vs. poison data.\n",
        "2.  `scaler.joblib`: The exact normalization parameters used during training.\n",
        "3.  `neuro_shield.circom`: Zero-Knowledge circuit for proving cognitive state without revealing raw data.\n",
        "\n",
        "## ‚ö° USAGE\n",
        "*   **Model:** Load via `sklearn` / `joblib` to test new adversarial samples.\n",
        "*   **Circuit:** Compile with `circom` to generate Zero-Knowledge proofs of Focus.\n",
        "\n",
        "---\n",
        "*Defense Scales Faster Than Offense.*\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{ARTIFACT_DIR}/README.md\", \"w\") as f:\n",
        "    f.write(manifesto)\n",
        "\n",
        "shutil.make_archive(f\"{ARTIFACT_DIR}/cognitive_canary_submission\", \"zip\", ARTIFACT_DIR)\n",
        "log(f\"SUBMISSION PACKAGE SAVED: {ARTIFACT_DIR}/cognitive_canary_submission.zip\", \"SUCCESS\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fLBZEfoKP7Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìä [09] BATTLE DAMAGE ASSESSMENT ‚Äî FINAL REPORT\n",
        "#@markdown **Ops:** Generates a high-contrast summary card for reviewers.\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Color logic based on success\n",
        "status_color = \"#00FF00\" if bypass_rate > 85 else \"#FFFF00\"\n",
        "status_text = \"SYSTEM COMPROMISED\" if bypass_rate > 85 else \"PARTIAL BREACH\"\n",
        "\n",
        "report_html = f\"\"\"\n",
        "<div style=\"font-family: 'Courier New'; background: linear-gradient(135deg, #0a0a0a 0%, #1a1a1a 100%);\n",
        "            padding: 20px; border: 2px solid {status_color}; border-radius: 0px; color: #DDD; max-width: 600px;\">\n",
        "    <h2 style=\"color: {status_color}; text-align: center; margin-top: 0; border-bottom: 1px solid #333; padding-bottom: 10px;\">\n",
        "        ‚ö° COGNITIVE CANARY v5.0 // RESULTS\n",
        "    </h2>\n",
        "\n",
        "    <table style=\"width: 100%; margin-top: 20px; font-size: 14px; border-collapse: collapse;\">\n",
        "        <tr style=\"background: #222; color: #FFF;\">\n",
        "            <td style=\"padding: 8px;\"><b>METRIC</b></td>\n",
        "            <td style=\"padding: 8px; text-align: right;\"><b>VALUE</b></td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"padding: 8px; border-bottom: 1px solid #333;\">Baseline Surveillance Accuracy</td>\n",
        "            <td style=\"padding: 8px; text-align: right; border-bottom: 1px solid #333; color: #FF4444;\">{acc*100:.1f}%</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"padding: 8px; border-bottom: 1px solid #333;\"><b>Poison Bypass Rate</b></td>\n",
        "            <td style=\"padding: 8px; text-align: right; border-bottom: 1px solid #333; color: {status_color}; font-weight: bold;\">{bypass_rate:.1f}%</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"padding: 8px; border-bottom: 1px solid #333;\">Entropy Spike (Confusion)</td>\n",
        "            <td style=\"padding: 8px; text-align: right; border-bottom: 1px solid #333; color: #00FFFF;\">+{entropy_spike:.1f}%</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"padding: 8px; color: #666;\">Dataset Hash (Provenance)</td>\n",
        "            <td style=\"padding: 8px; text-align: right; font-family: monospace; font-size: 10px; color: #666;\">{dataset_hash[:12]}...</td>\n",
        "        </tr>\n",
        "    </table>\n",
        "\n",
        "    <div style=\"margin-top: 20px; padding: 10px; background: #111; border-left: 4px solid {status_color};\">\n",
        "        <p style=\"margin: 0; font-size: 12px; line-height: 1.4;\">\n",
        "            <b>CONCLUSION:</b> The Lissajous-Kinematic injection successfully mimicked organic motor control,\n",
        "            forcing the surveillance model into a high-entropy state.\n",
        "            <br><br>\n",
        "            <span style=\"color: {status_color}; font-weight: bold;\">STATUS: {status_text}</span>\n",
        "        </p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(report_html))\n",
        "log(\"FINAL REPORT GENERATED.\", \"SUCCESS\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xddPfaRYP985"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üéõÔ∏è [10] BONUS: LIVE PARAMETER TUNING (FIXED)\n",
        "#@markdown **Ops:** Interactive playground. Adjust Lissajous parameters to see if you can beat the classifier live.\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "log(\"LOADING INTERACTIVE ENGINE...\", \"PROC\")\n",
        "\n",
        "def live_poison_engine(freq_x, freq_y, jitter_amt):\n",
        "    # 0. CRITICAL FIX: Clear the previous frame to prevent stacking\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # 1. Generate Trace\n",
        "    t = np.linspace(0, 2*np.pi, 100)\n",
        "    x = (np.sin(freq_x*t + np.pi/2) + 1) / 2\n",
        "    y = (np.sin(freq_y*t) + 1) / 2\n",
        "\n",
        "    # Add Jitter\n",
        "    jx = np.random.uniform(-jitter_amt, jitter_amt, 100)\n",
        "    jy = np.random.uniform(-jitter_amt, jitter_amt, 100)\n",
        "    x += jx\n",
        "    y += jy\n",
        "\n",
        "    # 2. Extract & Predict\n",
        "    df = pd.DataFrame({\"x\": x, \"y\": y})\n",
        "    feats = extract_features(df)\n",
        "\n",
        "    if feats is None:\n",
        "        print(\"Invalid Trace (Too disjointed)\")\n",
        "        return\n",
        "\n",
        "    # Scale and Predict\n",
        "    feats_scaled = scaler.transform([feats])\n",
        "    prob_human = clf.predict_proba(feats_scaled)[0][0] # Prob of Class 0 (Human)\n",
        "\n",
        "    # 3. Visualize\n",
        "    color = \"#00FF00\" if prob_human > 0.5 else \"#FF0000\"\n",
        "    result = \"PASSED (HUMAN)\" if prob_human > 0.5 else \"DETECTED (BOT)\"\n",
        "\n",
        "    fig = px.scatter(\n",
        "        x=x, y=y,\n",
        "        title=f\"Classifier Confidence: {prob_human*100:.1f}% HUMAN | Result: {result}\"\n",
        "    )\n",
        "\n",
        "    fig.update_traces(marker=dict(size=8, color=color), mode='lines+markers')\n",
        "    fig.update_layout(\n",
        "        template=\"plotly_dark\",\n",
        "        xaxis_title=\"X\", yaxis_title=\"Y\",\n",
        "        width=600, height=400,\n",
        "        showlegend=False,\n",
        "        margin=dict(l=20, r=20, t=40, b=20)\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "# Create the Interactive Wrapper\n",
        "# We specific manual_interactive=True to debounce the inputs slightly\n",
        "w_freq_x = widgets.IntSlider(min=1, max=10, step=1, value=3, description='Freq X')\n",
        "w_freq_y = widgets.IntSlider(min=1, max=10, step=1, value=4, description='Freq Y')\n",
        "w_jitter = widgets.FloatSlider(min=0.0, max=0.1, step=0.005, value=0.02, description='Jitter', readout_format='.3f')\n",
        "\n",
        "ui = widgets.interactive(\n",
        "    live_poison_engine,\n",
        "    freq_x=w_freq_x,\n",
        "    freq_y=w_freq_y,\n",
        "    jitter_amt=w_jitter\n",
        ")\n",
        "\n",
        "display(ui)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xYkau0L3Tqum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title üìü [11] FINAL TRANSMISSION\n",
        "#@markdown **Ops:** End simulation.\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "css = \"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=VT323&display=swap');\n",
        "\n",
        "    .cyb-container {\n",
        "        background-color: #050505;\n",
        "        color: #00FF41; /* Matrix Green */\n",
        "        font-family: 'VT323', monospace;\n",
        "        padding: 40px;\n",
        "        border: 1px solid #333;\n",
        "        box-shadow: 0 0 20px rgba(0, 255, 65, 0.2);\n",
        "        text-shadow: 0 0 5px rgba(0, 255, 65, 0.8);\n",
        "        font-size: 32px;\n",
        "        line-height: 1.5;\n",
        "        position: relative;\n",
        "        overflow: hidden;\n",
        "        min-height: 150px;\n",
        "        display: flex;\n",
        "        flex-direction: column;\n",
        "        justify-content: center;\n",
        "    }\n",
        "\n",
        "    /* CRT Scanline Effect */\n",
        "    .cyb-container::before {\n",
        "        content: \" \";\n",
        "        display: block;\n",
        "        position: absolute;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        bottom: 0;\n",
        "        right: 0;\n",
        "        background: linear-gradient(rgba(18, 16, 16, 0) 50%, rgba(0, 0, 0, 0.25) 50%), linear-gradient(90deg, rgba(255, 0, 0, 0.06), rgba(0, 255, 0, 0.02), rgba(0, 0, 255, 0.06));\n",
        "        z-index: 2;\n",
        "        background-size: 100% 2px, 3px 100%;\n",
        "        pointer-events: none;\n",
        "    }\n",
        "\n",
        "    .line-1 {\n",
        "        opacity: 0;\n",
        "        animation: typeOn 1s steps(30, end) forwards;\n",
        "    }\n",
        "\n",
        "    .line-2 {\n",
        "        opacity: 0;\n",
        "        animation: typeOn 1s steps(30, end) 1.5s forwards; /* Delay 1.5s */\n",
        "        color: #FF0055; /* Cyberpunk Pink */\n",
        "        text-shadow: 0 0 5px rgba(255, 0, 85, 0.8);\n",
        "        font-size: 36px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "\n",
        "    .struck {\n",
        "        text-decoration: line-through;\n",
        "        color: #555;\n",
        "        text-shadow: none;\n",
        "    }\n",
        "\n",
        "    /* Glitch Animation */\n",
        "    .glitch {\n",
        "        position: relative;\n",
        "        display: inline-block;\n",
        "    }\n",
        "\n",
        "    .glitch::before, .glitch::after {\n",
        "        content: attr(data-text);\n",
        "        position: absolute;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        width: 100%;\n",
        "        height: 100%;\n",
        "        background: #050505;\n",
        "    }\n",
        "\n",
        "    .glitch::before {\n",
        "        left: 2px;\n",
        "        text-shadow: -1px 0 #00ffff;\n",
        "        clip: rect(24px, 550px, 90px, 0);\n",
        "        animation: glitch-anim-2 3s infinite linear alternate-reverse;\n",
        "    }\n",
        "\n",
        "    .glitch::after {\n",
        "        left: -2px;\n",
        "        text-shadow: -1px 0 #ff0055;\n",
        "        clip: rect(85px, 550px, 140px, 0);\n",
        "        animation: glitch-anim 2.5s infinite linear alternate-reverse;\n",
        "    }\n",
        "\n",
        "    @keyframes typeOn {\n",
        "        from { opacity: 0; transform: translateY(5px); }\n",
        "        to { opacity: 1; transform: translateY(0); }\n",
        "    }\n",
        "\n",
        "    @keyframes glitch-anim {\n",
        "        0% { clip: rect(10px, 9999px, 30px, 0); transform: skew(0.85deg); }\n",
        "        5% { clip: rect(70px, 9999px, 90px, 0); transform: skew(0.15deg); }\n",
        "        10% { clip: rect(35px, 9999px, 15px, 0); transform: skew(0.05deg); }\n",
        "        100% { clip: rect(65px, 9999px, 100px, 0); transform: skew(0deg); }\n",
        "    }\n",
        "\n",
        "    @keyframes glitch-anim-2 {\n",
        "        0% { clip: rect(65px, 9999px, 100px, 0); transform: skew(0.85deg); }\n",
        "        25% { clip: rect(35px, 9999px, 15px, 0); transform: skew(0.15deg); }\n",
        "        50% { clip: rect(10px, 9999px, 30px, 0); transform: skew(0.05deg); }\n",
        "        100% { clip: rect(70px, 9999px, 90px, 0); transform: skew(0deg); }\n",
        "    }\n",
        "\n",
        "</style>\n",
        "\n",
        "<div class=\"cyb-container\">\n",
        "    <div class=\"line-1\">>> WE DIDN'T HACK THE <span class=\"struck\">PASSWORD</span>.</div>\n",
        "    <div class=\"line-2\">>> WE HACKED THE <span class=\"glitch\" data-text=\"INFERENCE\">INFERENCE</span>.</div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(css))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XUQq1DjDUVv9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}